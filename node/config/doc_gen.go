// Code generated by github.com/filecoin-project/lotus/node/config/cfgdocgen. DO NOT EDIT.

package config

type DocField struct {
	Name    string
	Type    string
	Comment string
}

var Doc = map[string][]DocField{
	"Backup": []DocField{
		{
			Name: "DisableMetadataLog",
			Type: "bool",

			Comment: `Note that in case of metadata corruption it might be much harder to recover
your node if metadata log is disabled`,
		},
	},
	"BitswapRetrievalConfig": []DocField{
		{
			Name: "BitswapPeerID",
			Type: "string",

			Comment: `The libp2p peer id used by booster-bitswap.
Run 'booster-bitswap init' to get the peer id.
When BitswapPeerID is not empty boostd will:
- listen on bitswap protocols on boostd's own peer id and proxy
requests to booster-bitswap
- advertise boostd's peer id in bitswap records to the content indexer
(bitswap clients connect to boostd, which proxies the requests to
booster-bitswap)
- list bitswap as an available transport on the retrieval transport protocol`,
		},
		{
			Name: "BitswapPublicAddresses",
			Type: "[]string",

			Comment: `Public multiaddresses for booster-bitswap.
If empty
- booster-bitswap is assumed to be running privately
- boostd acts as a proxy: it listens on bitswap protocols on boostd's own
peer id and forwards them to booster-bitswap
If public addresses are set
- boostd announces the booster-bitswap peer id to the indexer as an
extended provider
- clients make connections directly to the booster-bitswap process
(boostd does not act as a proxy)`,
		},
		{
			Name: "BitswapPrivKeyFile",
			Type: "string",

			Comment: `If operating in public mode, in order to announce booster-bitswap as an extended provider, this value must point to a
a file containing the booster-bitswap peer id's private key. Can be left blank when operating with protocol proxy.`,
		},
	},
	"Boost": []DocField{
		{
			Name: "ConfigVersion",
			Type: "int",

			Comment: `The version of the config file (used for migrations)`,
		},
		{
			Name: "Storage",
			Type: "StorageConfig",

			Comment: ``,
		},
		{
			Name: "SealerApiInfo",
			Type: "string",

			Comment: `The connect string for the sealing RPC API (lotus miner)`,
		},
		{
			Name: "SectorIndexApiInfo",
			Type: "string",

			Comment: `The connect string for the sector index RPC API (lotus miner)`,
		},
		{
			Name: "Dealmaking",
			Type: "DealmakingConfig",

			Comment: ``,
		},
		{
			Name: "Dealpublish",
			Type: "DealPublishConfig",

			Comment: ``,
		},
		{
			Name: "Wallets",
			Type: "WalletsConfig",

			Comment: ``,
		},
		{
			Name: "Graphql",
			Type: "GraphqlConfig",

			Comment: ``,
		},
		{
			Name: "Monitoring",
			Type: "MonitoringConfig",

			Comment: ``,
		},
		{
			Name: "Tracing",
			Type: "TracingConfig",

			Comment: ``,
		},
		{
			Name: "LocalIndexDirectory",
			Type: "LocalIndexDirectoryConfig",

			Comment: ``,
		},
		{
			Name: "ContractDeals",
			Type: "ContractDealsConfig",

			Comment: ``,
		},
		{
			Name: "HttpDownload",
			Type: "HttpDownloadConfig",

			Comment: ``,
		},
		{
			Name: "Retrievals",
			Type: "RetrievalConfig",

			Comment: ``,
		},
		{
			Name: "IndexProvider",
			Type: "IndexProviderConfig",

			Comment: ``,
		},
	},
	"Common": []DocField{
		{
			Name: "API",
			Type: "lotus_config.API",

			Comment: ``,
		},
		{
			Name: "Backup",
			Type: "lotus_config.Backup",

			Comment: ``,
		},
		{
			Name: "Libp2p",
			Type: "lotus_config.Libp2p",

			Comment: ``,
		},
		{
			Name: "Pubsub",
			Type: "lotus_config.Pubsub",

			Comment: ``,
		},
	},
	"ContractDealsConfig": []DocField{
		{
			Name: "Enabled",
			Type: "bool",

			Comment: `Whether to enable chain monitoring in order to accept contract deals`,
		},
		{
			Name: "AllowlistContracts",
			Type: "[]string",

			Comment: `Allowlist for contracts that this SP should accept deals from`,
		},
		{
			Name: "From",
			Type: "string",

			Comment: `From address for eth_ state call`,
		},
	},
	"DealPublishConfig": []DocField{
		{
			Name: "ManualDealPublish",
			Type: "bool",

			Comment: `When set to true, the user is responsible for publishing deals manually.
The values of MaxDealsPerPublishMsg and PublishMsgPeriod will be
ignored, and deals will remain in the pending state until manually published.`,
		},
		{
			Name: "PublishMsgPeriod",
			Type: "Duration",

			Comment: `When a deal is ready to publish, the amount of time to wait for more
deals to be ready to publish before publishing them all as a batch`,
		},
		{
			Name: "MaxDealsPerPublishMsg",
			Type: "uint64",

			Comment: `The maximum number of deals to include in a single PublishStorageDeals
message`,
		},
		{
			Name: "MaxPublishDealsFee",
			Type: "types.FIL",

			Comment: `The maximum collateral that the provider will put up against a deal,
as a multiplier of the minimum collateral bound
The maximum fee to pay when sending the PublishStorageDeals message`,
		},
	},
	"DealmakingConfig": []DocField{
		{
			Name: "ConsiderOnlineStorageDeals",
			Type: "bool",

			Comment: `When enabled, the miner can accept online deals`,
		},
		{
			Name: "ConsiderOfflineStorageDeals",
			Type: "bool",

			Comment: `When enabled, the miner can accept offline deals`,
		},
		{
			Name: "ConsiderOnlineRetrievalDeals",
			Type: "bool",

			Comment: `When enabled, the miner can accept retrieval deals`,
		},
		{
			Name: "ConsiderOfflineRetrievalDeals",
			Type: "bool",

			Comment: `When enabled, the miner can accept offline retrieval deals`,
		},
		{
			Name: "ConsiderVerifiedStorageDeals",
			Type: "bool",

			Comment: `When enabled, the miner can accept verified deals`,
		},
		{
			Name: "ConsiderUnverifiedStorageDeals",
			Type: "bool",

			Comment: `When enabled, the miner can accept unverified deals`,
		},
		{
			Name: "PieceCidBlocklist",
			Type: "[]cid.Cid",

			Comment: `A list of Data CIDs to reject when making deals`,
		},
		{
			Name: "ExpectedSealDuration",
			Type: "Duration",

			Comment: `Maximum expected amount of time getting the deal into a sealed sector will take
This includes the time the deal will need to get transferred and published
before being assigned to a sector`,
		},
		{
			Name: "MaxDealStartDelay",
			Type: "Duration",

			Comment: `Maximum amount of time proposed deal StartEpoch can be in the future.
This is applicable only for online deals as offline deals can take long duration
to import the data`,
		},
		{
			Name: "MaxProviderCollateralMultiplier",
			Type: "uint64",

			Comment: `The maximum collateral that the provider will put up against a deal,
as a multiplier of the minimum collateral bound`,
		},
		{
			Name: "MaxStagingDealsBytes",
			Type: "int64",

			Comment: `The maximum allowed disk usage size in bytes of downloaded deal data
that has not yet been passed to the sealing node by boost.
When the client makes a new deal proposal to download data from a host,
boost checks this config value against the sum of:
- the amount of data downloaded in the staging area
- the amount of data that is queued for download
- the amount of data in the proposed deal
If the total amount would exceed the limit, boost rejects the deal.
Set this value to 0 to indicate there is no limit.`,
		},
		{
			Name: "MaxStagingDealsPercentPerHost",
			Type: "uint64",

			Comment: `The percentage of MaxStagingDealsBytes that is allocated to each host.
When the client makes a new deal proposal to download data from a host,
boost checks this config value against the sum of:
- the amount of data downloaded from the host in the staging area
- the amount of data that is queued for download from the host
- the amount of data in the proposed deal
If the total amount would exceed the limit, boost rejects the deal.
Set this value to 0 to indicate there is no limit per host.`,
		},
		{
			Name: "StartEpochSealingBuffer",
			Type: "uint64",

			Comment: `Minimum start epoch buffer to give time for sealing of sector with deal.`,
		},
		{
			Name: "DealProposalLogDuration",
			Type: "Duration",

			Comment: `The amount of time to keep deal proposal logs for before cleaning them up.`,
		},
		{
			Name: "Filter",
			Type: "string",

			Comment: `A command used for fine-grained evaluation of storage deals
see https://boost.filecoin.io/configuration/deal-filters for more details`,
		},
		{
			Name: "IsUnsealedCacheExpiry",
			Type: "Duration",

			Comment: `How long to cache calls to check whether a sector is unsealed`,
		},
		{
			Name: "MaxTransferDuration",
			Type: "Duration",

			Comment: `The maximum amount of time a transfer can take before it fails`,
		},
		{
			Name: "RemoteCommp",
			Type: "bool",

			Comment: `Whether to do commp on the Boost node (local) or on the Sealer (remote)
Please note that this only works for v1.2.0 deals and not legacy deals`,
		},
		{
			Name: "MaxConcurrentLocalCommp",
			Type: "uint64",

			Comment: `The maximum number of commp processes to run in parallel on the local
boost process`,
		},
		{
			Name: "DealLogDurationDays",
			Type: "int",

			Comment: `The deal logs older than DealLogDurationDays are deleted from the logsDB
to keep the size of logsDB in check. Set the value as "0" to disable log cleanup`,
		},
		{
			Name: "SealingPipelineCacheTimeout",
			Type: "Duration",

			Comment: `The sealing pipeline status is cached by Boost if deal filters are enabled to avoid constant call to
lotus-miner API. SealingPipelineCacheTimeout defines cache timeout value in seconds. Default is 30 seconds.
Any value less than 0 will result in use of default`,
		},
		{
			Name: "FundsTaggingEnabled",
			Type: "bool",

			Comment: `Whether to enable tagging of funds. If enabled, each time a deal is
accepted boost will tag funds for that deal so that they cannot be used
for any other deal.`,
		},
	},
	"GraphqlConfig": []DocField{
		{
			Name: "ListenAddress",
			Type: "string",

			Comment: `The ip address the GraphQL server will bind to. Default: 127.0.0.1`,
		},
		{
			Name: "Port",
			Type: "uint64",

			Comment: `The port that the graphql server listens on`,
		},
	},
	"GraphsyncRetrievalConfig": []DocField{
		{
			Name: "SimultaneousTransfersForRetrieval",
			Type: "uint64",

			Comment: `The maximum number of parallel online data transfers for retrieval deals`,
		},
		{
			Name: "RetrievalLogDuration",
			Type: "Duration",

			Comment: `The amount of time to keep retrieval deal logs for before cleaning them up.
Note RetrievalLogDuration should exceed the StalledRetrievalTimeout as the
logs db is leveraged for pruning stalled retrievals.`,
		},
		{
			Name: "StalledRetrievalTimeout",
			Type: "Duration",

			Comment: `The amount of time stalled retrieval deals will remain open before being canceled.`,
		},
		{
			Name: "GraphsyncStorageAccessApiInfo",
			Type: "[]string",

			Comment: `The connect strings for the RPC APIs of each miner that boost can read
sector data from when serving graphsync retrievals.
If this parameter is not set, boost will serve data from the endpoint
configured in SectorIndexApiInfo.`,
		},
		{
			Name: "RetrievalFilter",
			Type: "string",

			Comment: `A command used for fine-grained evaluation of retrieval deals
see https://boost.filecoin.io/configuration/deal-filters for more details`,
		},
	},
	"HTTPRetrievalConfig": []DocField{
		{
			Name: "HTTPRetrievalMultiaddr",
			Type: "string",

			Comment: `The public multi-address for retrieving deals with booster-http.
Note: Must be in multiaddr format, eg /dns/foo.com/tcp/443/https`,
		},
	},
	"HttpDownloadConfig": []DocField{
		{
			Name: "HttpTransferMaxConcurrentDownloads",
			Type: "uint64",

			Comment: `The maximum number of concurrent storage deal HTTP downloads.
Note that this is a soft maximum; if some downloads stall,
more downloads are allowed to start.`,
		},
		{
			Name: "HttpTransferStallCheckPeriod",
			Type: "Duration",

			Comment: `The period between checking if downloads have stalled.`,
		},
		{
			Name: "HttpTransferStallTimeout",
			Type: "Duration",

			Comment: `The time that can elapse before a download is considered stalled (and
another concurrent download is allowed to start).`,
		},
		{
			Name: "NChunks",
			Type: "int",

			Comment: `NChunks is a number of chunks to split HTTP downloads into. Each chunk is downloaded in the goroutine of its own
which improves the overall download speed. NChunks is always equal to 1 for libp2p transport because libp2p server
doesn't support range requests yet. NChunks must be greater than 0 and less than 16, with the default of 5.`,
		},
		{
			Name: "AllowPrivateIPs",
			Type: "bool",

			Comment: `AllowPrivateIPs defines whether boost should allow HTTP downloads from private IPs as per https://en.wikipedia.org/wiki/Private_network.
The default is false.`,
		},
	},
	"IndexProviderAnnounceConfig": []DocField{
		{
			Name: "AnnounceOverHttp",
			Type: "bool",

			Comment: `Make a direct announcement to a list of indexing nodes over http.
Note that announcements are already made over pubsub regardless
of this setting.`,
		},
		{
			Name: "DirectAnnounceURLs",
			Type: "[]string",

			Comment: `The list of URLs of indexing nodes to announce to.`,
		},
	},
	"IndexProviderConfig": []DocField{
		{
			Name: "Enable",
			Type: "bool",

			Comment: `Enable set whether to enable indexing announcement to the network and expose endpoints that
allow indexer nodes to process announcements. Enabled by default.`,
		},
		{
			Name: "EntriesCacheCapacity",
			Type: "int",

			Comment: `EntriesCacheCapacity sets the maximum capacity to use for caching the indexing advertisement
entries. Defaults to 1024 if not specified. The cache is evicted using LRU policy. The
maximum storage used by the cache is a factor of EntriesCacheCapacity, EntriesChunkSize and
the length of multihashes being advertised. For example, advertising 128-bit long multihashes
with the default EntriesCacheCapacity, and EntriesChunkSize means the cache size can grow to
256MiB when full.`,
		},
		{
			Name: "EntriesChunkSize",
			Type: "int",

			Comment: `EntriesChunkSize sets the maximum number of multihashes to include in a single entries chunk.
Defaults to 16384 if not specified. Note that chunks are chained together for indexing
advertisements that include more multihashes than the configured EntriesChunkSize.`,
		},
		{
			Name: "TopicName",
			Type: "string",

			Comment: `TopicName sets the topic name on which the changes to the advertised content are announced.
If not explicitly specified, the topic name is automatically inferred from the network name
in following format: '/indexer/ingest/<network-name>'
Defaults to empty, which implies the topic name is inferred from network name.`,
		},
		{
			Name: "PurgeCacheOnStart",
			Type: "bool",

			Comment: `PurgeCacheOnStart sets whether to clear any cached entries chunks when the provider engine
starts. By default, the cache is rehydrated from previously cached entries stored in
datastore if any is present.`,
		},
		{
			Name: "WebHost",
			Type: "string",

			Comment: `The network indexer host that the web UI should link to for published announcements`,
		},
		{
			Name: "Announce",
			Type: "IndexProviderAnnounceConfig",

			Comment: ``,
		},
		{
			Name: "HttpPublisher",
			Type: "IndexProviderHttpPublisherConfig",

			Comment: ``,
		},
		{
			Name: "DataTransferPublisher",
			Type: "bool",

			Comment: `Set this to true to use the legacy data-transfer/graphsync publisher.
This should only be used as a temporary fall-back if publishing ipnisync
over libp2p or HTTP is not working, and publishing over
data-transfer/graphsync was previously working.`,
		},
	},
	"IndexProviderHttpPublisherConfig": []DocField{
		{
			Name: "Enabled",
			Type: "bool",

			Comment: `If enabled, requests are served over HTTP instead of libp2p.`,
		},
		{
			Name: "PublicHostname",
			Type: "string",

			Comment: `Set the public hostname / IP for the index provider listener.
eg "82.129.73.111"
This is usually the same as the for the boost node.`,
		},
		{
			Name: "Port",
			Type: "int",

			Comment: `Set the port on which to listen for index provider requests over HTTP.
Note that this port must be open on the firewall.`,
		},
		{
			Name: "WithLibp2p",
			Type: "bool",

			Comment: `Set this to true to publish HTTP over libp2p in addition to plain HTTP,
Otherwise, the publisher will publish content advertisements using only
plain HTTP if Enabled is true.`,
		},
	},
	"LocalIndexDirectoryConfig": []DocField{
		{
			Name: "Yugabyte",
			Type: "LocalIndexDirectoryYugabyteConfig",

			Comment: ``,
		},
		{
			Name: "Leveldb",
			Type: "LocalIndexDirectoryLeveldbConfig",

			Comment: ``,
		},
		{
			Name: "ParallelAddIndexLimit",
			Type: "int",

			Comment: `The maximum number of add index operations allowed to execute in parallel.
The add index operation is executed when a new deal is created - it fetches
the piece from the sealing subsystem, creates an index of where each block
is in the piece, and adds the index to the local index directory.`,
		},
		{
			Name: "AddIndexConcurrency",
			Type: "int",

			Comment: `AddIndexConcurrency sets the number of concurrent tasks that each add index operation is split into.
This setting is usefull to better utilise bandwidth between boostd and boost-data. The default value is 8.`,
		},
		{
			Name: "EmbeddedServicePort",
			Type: "uint64",

			Comment: `The port that the embedded local index directory data service runs on.
Set this value to zero to disable the embedded local index directory data service
(in that case the local index directory data service must be running externally)`,
		},
		{
			Name: "ServiceApiInfo",
			Type: "string",

			Comment: `The connect string for the local index directory data service RPC API eg "ws://localhost:8042"
Set this value to "" if the local index directory data service is embedded.`,
		},
		{
			Name: "ServiceRPCTimeout",
			Type: "Duration",

			Comment: `The RPC timeout when making requests to the boostd-data service`,
		},
		{
			Name: "EnablePieceDoctor",
			Type: "bool",

			Comment: `PieceDoctor runs a continuous background process to check each piece in LID for retrievability`,
		},
		{
			Name: "LidCleanupInterval",
			Type: "Duration",

			Comment: `Interval at which LID clean up job should rerun. The cleanup entails removing indices and metadata
for the expired/slashed deals. Disabled if set to '0s'. Please DO NOT set a value lower than 6 hours
as this task consumes considerable resources and time`,
		},
	},
	"LocalIndexDirectoryLeveldbConfig": []DocField{
		{
			Name: "Enabled",
			Type: "bool",

			Comment: ``,
		},
	},
	"LocalIndexDirectoryYugabyteConfig": []DocField{
		{
			Name: "Enabled",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "ConnectString",
			Type: "string",

			Comment: `The yugabyte postgres connect string eg "postgresql://postgres:postgres@localhost"`,
		},
		{
			Name: "Hosts",
			Type: "[]string",

			Comment: `The yugabyte cassandra hosts eg ["127.0.0.1"]`,
		},
		{
			Name: "Username",
			Type: "string",

			Comment: `The yugabyte cassandra username eg "cassandra"`,
		},
		{
			Name: "Password",
			Type: "string",

			Comment: `The yugabyte cassandra password eg "cassandra"`,
		},
	},
	"MonitoringConfig": []DocField{
		{
			Name: "MpoolAlertEpochs",
			Type: "int64",

			Comment: `The number of epochs after which alert is generated for a local pending
message in lotus mpool`,
		},
	},
	"RetrievalConfig": []DocField{
		{
			Name: "Graphsync",
			Type: "GraphsyncRetrievalConfig",

			Comment: ``,
		},
		{
			Name: "Bitswap",
			Type: "BitswapRetrievalConfig",

			Comment: ``,
		},
		{
			Name: "HTTP",
			Type: "HTTPRetrievalConfig",

			Comment: ``,
		},
	},
	"StorageConfig": []DocField{
		{
			Name: "ParallelFetchLimit",
			Type: "int",

			Comment: `The maximum number of concurrent fetch operations to the storage subsystem`,
		},
		{
			Name: "StorageListRefreshDuration",
			Type: "Duration",

			Comment: `How frequently Boost should refresh the state of sectors with Lotus. (default: 1hour)
When run, Boost will trigger a storage redeclare on the miner in addition to a storage list.
This ensures that index metadata for sectors reflects their status (removed, unsealed, etc).`,
		},
		{
			Name: "RedeclareOnStorageListRefresh",
			Type: "bool",

			Comment: `Whether or not Boost should have lotus redeclare its storage list (default: true).
Disable this if you wish to manually handle the refresh. If manually managing the redeclare
and it is not triggered, retrieval quality for users will be impacted.`,
		},
	},
	"TracingConfig": []DocField{
		{
			Name: "Enabled",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "ServiceName",
			Type: "string",

			Comment: ``,
		},
		{
			Name: "Endpoint",
			Type: "string",

			Comment: ``,
		},
	},
	"WalletsConfig": []DocField{
		{
			Name: "Miner",
			Type: "string",

			Comment: `The miner ID`,
		},
		{
			Name: "PublishStorageDeals",
			Type: "string",

			Comment: `The wallet used to send PublishStorageDeals messages.
Must be a control or worker address of the miner.`,
		},
		{
			Name: "DealCollateral",
			Type: "string",

			Comment: `The wallet used as the source for storage deal collateral`,
		},
		{
			Name: "PledgeCollateral",
			Type: "string",

			Comment: `Deprecated: Renamed to DealCollateral`,
		},
	},
	"lotus_config.API": []DocField{
		{
			Name: "ListenAddress",
			Type: "string",

			Comment: `Binding address for the Lotus API`,
		},
		{
			Name: "RemoteListenAddress",
			Type: "string",

			Comment: ``,
		},
		{
			Name: "Timeout",
			Type: "Duration",

			Comment: ``,
		},
	},
	"lotus_config.ApisConfig": []DocField{
		{
			Name: "ChainApiInfo",
			Type: "[]string",

			Comment: `ChainApiInfo is the API endpoint for the Lotus daemon.`,
		},
		{
			Name: "StorageRPCSecret",
			Type: "string",

			Comment: `RPC Secret for the storage subsystem.
If integrating with lotus-miner this must match the value from
cat ~/.lotusminer/keystore/MF2XI2BNNJ3XILLQOJUXMYLUMU | jq -r .PrivateKey`,
		},
	},
	"lotus_config.Backup": []DocField{
		{
			Name: "DisableMetadataLog",
			Type: "bool",

			Comment: `Note that in case of metadata corruption it might be much harder to recover
your node if metadata log is disabled`,
		},
	},
	"lotus_config.BatchFeeConfig": []DocField{
		{
			Name: "Base",
			Type: "types.FIL",

			Comment: ``,
		},
		{
			Name: "PerSector",
			Type: "types.FIL",

			Comment: ``,
		},
	},
	"lotus_config.ChainIndexerConfig": []DocField{
		{
			Name: "EnableIndexer",
			Type: "bool",

			Comment: `If EnableEthRPC or EnableActorEventsAPI are set to true, the ChainIndexer must be enabled using
this option to avoid errors at startup.`,
		},
		{
			Name: "GCRetentionEpochs",
			Type: "int64",

			Comment: `Default: 0 (GC disabled)`,
		},
		{
			Name: "ReconcileEmptyIndex",
			Type: "bool",

			Comment: `Note: The number of tipsets reconciled (i.e. indexed) during this process can be
controlled using the MaxReconcileTipsets option.`,
		},
		{
			Name: "MaxReconcileTipsets",
			Type: "uint64",

			Comment: `Note: Setting this value too low may result in incomplete indexing, while setting it too high
may increase startup time.`,
		},
	},
	"lotus_config.Chainstore": []DocField{
		{
			Name: "EnableSplitstore",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "Splitstore",
			Type: "Splitstore",

			Comment: ``,
		},
	},
	"lotus_config.Common": []DocField{
		{
			Name: "API",
			Type: "API",

			Comment: ``,
		},
		{
			Name: "Backup",
			Type: "Backup",

			Comment: ``,
		},
		{
			Name: "Logging",
			Type: "Logging",

			Comment: ``,
		},
	},
	"lotus_config.DealmakingConfig": []DocField{
		{
			Name: "StartEpochSealingBuffer",
			Type: "uint64",

			Comment: `Minimum start epoch buffer to give time for sealing of sector with deal.`,
		},
	},
	"lotus_config.EventsConfig": []DocField{
		{
			Name: "EnableActorEventsAPI",
			Type: "bool",

			Comment: `EnableActorEventsAPI enables the Actor events API that enables clients to consume events
emitted by (smart contracts + built-in Actors).
Note: Setting this to true will also require that ChainIndexer is enabled, otherwise it will cause an error at startup.
Set EnableIndexer in the ChainIndexer section of the config to true to enable the ChainIndexer.`,
		},
		{
			Name: "FilterTTL",
			Type: "Duration",

			Comment: `FilterTTL specifies the time to live for actor event filters. Filters that haven't been accessed longer than
this time become eligible for automatic deletion. Filters consume resources, so if they are unused they
should not be retained.`,
		},
		{
			Name: "MaxFilters",
			Type: "int",

			Comment: `MaxFilters specifies the maximum number of filters that may exist at any one time.
Multi-tenant environments may want to increase this value to serve a larger number of clients. If using
lotus-gateway, this global limit can be coupled with --eth-max-filters-per-conn which limits the number
of filters per connection.`,
		},
		{
			Name: "MaxFilterResults",
			Type: "int",

			Comment: `MaxFilterResults specifies the maximum number of results that can be accumulated by an actor event filter.`,
		},
		{
			Name: "MaxFilterHeightRange",
			Type: "uint64",

			Comment: `MaxFilterHeightRange specifies the maximum range of heights that can be used in a filter (to avoid querying
the entire chain)`,
		},
	},
	"lotus_config.FaultReporterConfig": []DocField{
		{
			Name: "EnableConsensusFaultReporter",
			Type: "bool",

			Comment: `EnableConsensusFaultReporter controls whether the node will monitor and
report consensus faults. When enabled, the node will watch for malicious
behaviors like double-mining and parent grinding, and submit reports to the
network. This can earn reporter rewards, but is not guaranteed. Nodes should
enable fault reporting with care, as it may increase resource usage, and may
generate gas fees without earning rewards.`,
		},
		{
			Name: "ConsensusFaultReporterDataDir",
			Type: "string",

			Comment: `ConsensusFaultReporterDataDir is the path where fault reporter state will be
persisted. This directory should have adequate space and permissions for the
node process.`,
		},
		{
			Name: "ConsensusFaultReporterAddress",
			Type: "string",

			Comment: `ConsensusFaultReporterAddress is the wallet address used for submitting
ReportConsensusFault messages. It will pay for gas fees, and receive any
rewards. This address should have adequate funds to cover gas fees.`,
		},
	},
	"lotus_config.FeeConfig": []DocField{
		{
			Name: "DefaultMaxFee",
			Type: "types.FIL",

			Comment: ``,
		},
	},
	"lotus_config.FevmConfig": []DocField{
		{
			Name: "EnableEthRPC",
			Type: "bool",

			Comment: `EnableEthRPC enables eth_ RPC methods.
Note: Setting this to true will also require that ChainIndexer is enabled, otherwise it will cause an error at startup.
Set EnableIndexer in the ChainIndexer section of the config to true to enable the ChainIndexer.`,
		},
		{
			Name: "EthTraceFilterMaxResults",
			Type: "uint64",

			Comment: `EthTraceFilterMaxResults sets the maximum results returned per request by trace_filter`,
		},
		{
			Name: "EthBlkCacheSize",
			Type: "int",

			Comment: `EthBlkCacheSize specifies the size of the cache used for caching Ethereum blocks.
This cache enhances the performance of the eth_getBlockByHash RPC call by minimizing the need to access chain state for
recently requested blocks that are already cached.
The default size of the cache is 500 blocks.
Note: Setting this value to 0 disables the cache.`,
		},
	},
	"lotus_config.FullNode": []DocField{
		{
			Name: "Libp2p",
			Type: "Libp2p",

			Comment: ``,
		},
		{
			Name: "Pubsub",
			Type: "Pubsub",

			Comment: ``,
		},
		{
			Name: "Wallet",
			Type: "Wallet",

			Comment: ``,
		},
		{
			Name: "Fees",
			Type: "FeeConfig",

			Comment: ``,
		},
		{
			Name: "Chainstore",
			Type: "Chainstore",

			Comment: ``,
		},
		{
			Name: "Fevm",
			Type: "FevmConfig",

			Comment: ``,
		},
		{
			Name: "Events",
			Type: "EventsConfig",

			Comment: ``,
		},
		{
			Name: "ChainIndexer",
			Type: "ChainIndexerConfig",

			Comment: ``,
		},
		{
			Name: "FaultReporter",
			Type: "FaultReporterConfig",

			Comment: ``,
		},
	},
	"lotus_config.HarmonyDB": []DocField{
		{
			Name: "Hosts",
			Type: "[]string",

			Comment: `HOSTS is a list of hostnames to nodes running YugabyteDB
in a cluster. Only 1 is required`,
		},
		{
			Name: "Username",
			Type: "string",

			Comment: `The Yugabyte server's username with full credentials to operate on Lotus' Database. Blank for default.`,
		},
		{
			Name: "Password",
			Type: "string",

			Comment: `The password for the related username. Blank for default.`,
		},
		{
			Name: "Database",
			Type: "string",

			Comment: `The database (logical partition) within Yugabyte. Blank for default.`,
		},
		{
			Name: "Port",
			Type: "string",

			Comment: `The port to find Yugabyte. Blank for default.`,
		},
	},
	"lotus_config.JournalConfig": []DocField{
		{
			Name: "//Events",
			Type: "of",

			Comment: ``,
		},
		{
			Name: "DisabledEvents",
			Type: "string",

			Comment: ``,
		},
	},
	"lotus_config.Libp2p": []DocField{
		{
			Name: "ListenAddresses",
			Type: "[]string",

			Comment: `Binding address for the libp2p host - 0 means random port.
Format: multiaddress; see https://multiformats.io/multiaddr/`,
		},
		{
			Name: "AnnounceAddresses",
			Type: "[]string",

			Comment: `Addresses to explicitally announce to other peers. If not specified,
all interface addresses are announced
Format: multiaddress`,
		},
		{
			Name: "NoAnnounceAddresses",
			Type: "[]string",

			Comment: `Addresses to not announce
Format: multiaddress`,
		},
		{
			Name: "BootstrapPeers",
			Type: "[]string",

			Comment: ``,
		},
		{
			Name: "ProtectedPeers",
			Type: "[]string",

			Comment: ``,
		},
		{
			Name: "DisableNatPortMap",
			Type: "bool",

			Comment: `When not disabled (default), lotus asks NAT devices (e.g., routers), to
open up an external port and forward it to the port lotus is running on.
When this works (i.e., when your router supports NAT port forwarding),
it makes the local lotus node accessible from the public internet`,
		},
		{
			Name: "ConnMgrLow",
			Type: "uint",

			Comment: `ConnMgrLow is the number of connections that the basic connection manager
will trim down to.`,
		},
		{
			Name: "ConnMgrHigh",
			Type: "uint",

			Comment: `ConnMgrHigh is the number of connections that, when exceeded, will trigger
a connection GC operation. Note: protected/recently formed connections don't
count towards this limit.`,
		},
		{
			Name: "ConnMgrGrace",
			Type: "Duration",

			Comment: `ConnMgrGrace is a time duration that new connections are immune from being
closed by the connection manager.`,
		},
	},
	"lotus_config.Logging": []DocField{
		{
			Name: "SubsystemLevels",
			Type: "map[string]string",

			Comment: `SubsystemLevels specify per-subsystem log levels`,
		},
	},
	"lotus_config.MinerAddressConfig": []DocField{
		{
			Name: "PreCommitControl",
			Type: "[]string",

			Comment: `Addresses to send PreCommit messages from`,
		},
		{
			Name: "CommitControl",
			Type: "[]string",

			Comment: `Addresses to send Commit messages from`,
		},
		{
			Name: "TerminateControl",
			Type: "[]string",

			Comment: ``,
		},
		{
			Name: "DealPublishControl",
			Type: "[]string",

			Comment: ``,
		},
		{
			Name: "DisableOwnerFallback",
			Type: "bool",

			Comment: `DisableOwnerFallback disables usage of the owner address for messages
sent automatically`,
		},
		{
			Name: "DisableWorkerFallback",
			Type: "bool",

			Comment: `DisableWorkerFallback disables usage of the worker address for messages
sent automatically, if control addresses are configured.
A control address that doesn't have enough funds will still be chosen
over the worker address if this flag is set.`,
		},
	},
	"lotus_config.MinerFeeConfig": []DocField{
		{
			Name: "MaxPreCommitGasFee",
			Type: "types.FIL",

			Comment: ``,
		},
		{
			Name: "MaxCommitGasFee",
			Type: "types.FIL",

			Comment: ``,
		},
		{
			Name: "MaxPreCommitBatchGasFee",
			Type: "BatchFeeConfig",

			Comment: `maxBatchFee = maxBase + maxPerSector * nSectors`,
		},
		{
			Name: "MaxCommitBatchGasFee",
			Type: "BatchFeeConfig",

			Comment: ``,
		},
		{
			Name: "MaxTerminateGasFee",
			Type: "types.FIL",

			Comment: ``,
		},
		{
			Name: "MaxWindowPoStGasFee",
			Type: "types.FIL",

			Comment: `WindowPoSt is a high-value operation, so the default fee should be high.`,
		},
		{
			Name: "MaxPublishDealsFee",
			Type: "types.FIL",

			Comment: ``,
		},
		{
			Name: "MaxMarketBalanceAddFee",
			Type: "types.FIL",

			Comment: ``,
		},
		{
			Name: "MaximizeWindowPoStFeeCap",
			Type: "bool",

			Comment: ``,
		},
	},
	"lotus_config.MinerSubsystemConfig": []DocField{
		{
			Name: "EnableMining",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "EnableSealing",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "EnableSectorStorage",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "EnableSectorIndexDB",
			Type: "bool",

			Comment: `When enabled, the sector index will reside in an external database
as opposed to the local KV store in the miner process
This is useful to allow workers to bypass the lotus miner to access sector information`,
		},
		{
			Name: "SealerApiInfo",
			Type: "string",

			Comment: ``,
		},
		{
			Name: "SectorIndexApiInfo",
			Type: "string",

			Comment: ``,
		},
		{
			Name: "DisableWindowPoSt",
			Type: "bool",

			Comment: `When window post is enabled, the miner will automatically submit window post proofs
for all sectors that are eligible for window post
IF WINDOW POST IS DISABLED, THE MINER WILL NOT SUBMIT WINDOW POST PROOFS
THIS WILL RESULT IN FAULTS AND PENALTIES IF NO OTHER MECHANISM IS RUNNING
TO SUBMIT WINDOW POST PROOFS.
Note: This option is entirely disabling the window post scheduler,
not just the builtin PoSt computation like Proving.DisableBuiltinWindowPoSt.
This option will stop lotus-miner from performing any actions related
to window post, including scheduling, submitting proofs, and recovering
sectors.`,
		},
		{
			Name: "DisableWinningPoSt",
			Type: "bool",

			Comment: `When winning post is disabled, the miner process will NOT attempt to mine
blocks. This should only be set when there's an external process mining
blocks on behalf of the miner.
When disabled and no external block producers are configured, all potential
block rewards will be missed!`,
		},
	},
	"lotus_config.ProvingConfig": []DocField{
		{
			Name: "ParallelCheckLimit",
			Type: "int",

			Comment: `After changing this option, confirm that the new value works in your setup by invoking
'lotus-miner proving compute window-post 0'`,
		},
		{
			Name: "SingleCheckTimeout",
			Type: "Duration",

			Comment: `WARNING: Setting this value too low risks in sectors being skipped even though they are accessible, just reading the
test challenge took longer than this timeout
WARNING: Setting this value too high risks missing PoSt deadline in case IO operations related to this sector are
blocked (e.g. in case of disconnected NFS mount)`,
		},
		{
			Name: "PartitionCheckTimeout",
			Type: "Duration",

			Comment: `WARNING: Setting this value too low risks in sectors being skipped even though they are accessible, just reading the
test challenge took longer than this timeout
WARNING: Setting this value too high risks missing PoSt deadline in case IO operations related to this partition are
blocked or slow`,
		},
		{
			Name: "DisableBuiltinWindowPoSt",
			Type: "bool",

			Comment: `After changing this option, confirm that the new value works in your setup by invoking
'lotus-miner proving compute window-post 0'`,
		},
		{
			Name: "DisableBuiltinWinningPoSt",
			Type: "bool",

			Comment: `WARNING: If no WinningPoSt workers are connected, Winning PoSt WILL FAIL resulting in lost block rewards.
Before enabling this option, make sure your PoSt workers work correctly.`,
		},
		{
			Name: "DisableWDPoStPreChecks",
			Type: "bool",

			Comment: `After changing this option, confirm that the new value works in your setup by invoking
'lotus-miner proving compute window-post 0'`,
		},
		{
			Name: "//",
			Type: "//",

			Comment: `A single partition may contain up to 2349 32GiB sectors, or 2300 64GiB sectors.`,
		},
		{
			Name: "MaxPartitionsPerPoStMessage",
			Type: "int",

			Comment: `Setting this value above the network limit has no effect`,
		},
		{
			Name: "MaxPartitionsPerRecoveryMessage",
			Type: "int",

			Comment: `In some cases when submitting DeclareFaultsRecovered messages,
there may be too many recoveries to fit in a BlockGasLimit.
In those cases it may be necessary to set this value to something low (eg 1);
Note that setting this value lower may result in less efficient gas use - more messages will be sent than needed,
resulting in more total gas use (but each message will have lower gas limit)`,
		},
		{
			Name: "SingleRecoveringPartitionPerPostMessage",
			Type: "bool",

			Comment: `Note that setting this value lower may result in less efficient gas use - more messages will be sent,
to prove each deadline, resulting in more total gas use (but each message will have lower gas limit)`,
		},
	},
	"lotus_config.Pubsub": []DocField{
		{
			Name: "Bootstrapper",
			Type: "bool",

			Comment: `Run the node in bootstrap-node mode`,
		},
		{
			Name: "DirectPeers",
			Type: "[]string",

			Comment: `DirectPeers specifies peers with direct peering agreements. These peers are
connected outside of the mesh, with all (valid) message unconditionally
forwarded to them. The router will maintain open connections to these peers.
Note that the peering agreement should be reciprocal with direct peers
symmetrically configured at both ends.
Type: Array of multiaddress peerinfo strings, must include peerid (/p2p/12D3K...`,
		},
		{
			Name: "IPColocationWhitelist",
			Type: "[]string",

			Comment: ``,
		},
		{
			Name: "RemoteTracer",
			Type: "string",

			Comment: ``,
		},
		{
			Name: "JsonTracer",
			Type: "string",

			Comment: `Path to file that will be used to output tracer content in JSON format.
If present tracer will save data to defined file.
Format: file path`,
		},
		{
			Name: "ElasticSearchTracer",
			Type: "string",

			Comment: `Connection string for elasticsearch instance.
If present tracer will save data to elasticsearch.
Format: https://<username>:<password>@<elasticsearch_url>:<port>/`,
		},
		{
			Name: "ElasticSearchIndex",
			Type: "string",

			Comment: `Name of elasticsearch index that will be used to save tracer data.
This property is used only if ElasticSearchTracer propery is set.`,
		},
		{
			Name: "TracerSourceAuth",
			Type: "string",

			Comment: `Auth token that will be passed with logs to elasticsearch - used for weighted peers score.`,
		},
	},
	"lotus_config.SealerConfig": []DocField{
		{
			Name: "ParallelFetchLimit",
			Type: "int",

			Comment: ``,
		},
		{
			Name: "AllowSectorDownload",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowAddPiece",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowPreCommit1",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowPreCommit2",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowCommit",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowUnseal",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowReplicaUpdate",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowProveReplicaUpdate2",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "AllowRegenSectorKey",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "LocalWorkerName",
			Type: "string",

			Comment: `LocalWorkerName specifies a custom name for the builtin worker.
If set to an empty string (default) os hostname will be used`,
		},
		{
			Name: "Assigner",
			Type: "string",

			Comment: `Assigner specifies the worker assigner to use when scheduling tasks.
"utilization" (default) - assign tasks to workers with lowest utilization.
"spread" - assign tasks to as many distinct workers as possible.`,
		},
		{
			Name: "DisallowRemoteFinalize",
			Type: "bool",

			Comment: `DisallowRemoteFinalize when set to true will force all Finalize tasks to
run on workers with local access to both long-term storage and the sealing
path containing the sector.
--
WARNING: Only set this if all workers have access to long-term storage
paths. If this flag is enabled, and there are workers without long-term
storage access, sectors will not be moved from them, and Finalize tasks
will appear to be stuck.
--
If you see stuck Finalize tasks after enabling this setting, check
'lotus-miner sealing sched-diag' and 'lotus-miner storage find [sector num]'`,
		},
		{
			Name: "ResourceFiltering",
			Type: "ResourceFilteringStrategy",

			Comment: `ResourceFiltering instructs the system which resource filtering strategy
to use when evaluating tasks against this worker. An empty value defaults
to "hardware".`,
		},
	},
	"lotus_config.SealingConfig": []DocField{
		{
			Name: "MaxWaitDealsSectors",
			Type: "uint64",

			Comment: `Upper bound on how many sectors can be waiting for more deals to be packed in it before it begins sealing at any given time.
If the miner is accepting multiple deals in parallel, up to MaxWaitDealsSectors of new sectors will be created.
If more than MaxWaitDealsSectors deals are accepted in parallel, only MaxWaitDealsSectors deals will be processed in parallel
Note that setting this number too high in relation to deal ingestion rate may result in poor sector packing efficiency
0 = no limit`,
		},
		{
			Name: "MaxSealingSectors",
			Type: "uint64",

			Comment: `Upper bound on how many sectors can be sealing+upgrading at the same time when creating new CC sectors (0 = unlimited)`,
		},
		{
			Name: "MaxSealingSectorsForDeals",
			Type: "uint64",

			Comment: `Upper bound on how many sectors can be sealing+upgrading at the same time when creating new sectors with deals (0 = unlimited)`,
		},
		{
			Name: "PreferNewSectorsForDeals",
			Type: "bool",

			Comment: `Prefer creating new sectors even if there are sectors Available for upgrading.
This setting combined with MaxUpgradingSectors set to a value higher than MaxSealingSectorsForDeals makes it
possible to use fast sector upgrades to handle high volumes of storage deals, while still using the simple sealing
flow when the volume of storage deals is lower.`,
		},
		{
			Name: "MaxUpgradingSectors",
			Type: "uint64",

			Comment: `Upper bound on how many sectors can be sealing+upgrading at the same time when upgrading CC sectors with deals (0 = MaxSealingSectorsForDeals)`,
		},
		{
			Name: "MinUpgradeSectorExpiration",
			Type: "uint64",

			Comment: `Note that if all deals waiting in the input queue have lifetimes longer than this value, upgrade sectors will be
required to have expiration of at least the soonest-ending deal`,
		},
		{
			Name: "MinTargetUpgradeSectorExpiration",
			Type: "uint64",

			Comment: `DEPRECATED: Target expiration is no longer used`,
		},
		{
			Name: "CommittedCapacitySectorLifetime",
			Type: "Duration",

			Comment: `CommittedCapacitySectorLifetime is the duration a Committed Capacity (CC) sector will
live before it must be extended or converted into sector containing deals before it is
terminated. Value must be between 180-1278 days (1278 in nv21, 540 before nv21).`,
		},
		{
			Name: "WaitDealsDelay",
			Type: "Duration",

			Comment: `Period of time that a newly created sector will wait for more deals to be packed in to before it starts to seal.
Sectors which are fully filled will start sealing immediately`,
		},
		{
			Name: "AlwaysKeepUnsealedCopy",
			Type: "bool",

			Comment: `Whether to keep unsealed copies of deal data regardless of whether the client requested that. This lets the miner
avoid the relatively high cost of unsealing the data later, at the cost of more storage space`,
		},
		{
			Name: "FinalizeEarly",
			Type: "bool",

			Comment: `Run sector finalization before submitting sector proof to the chain`,
		},
		{
			Name: "MakeNewSectorForDeals",
			Type: "bool",

			Comment: `Whether new sectors are created to pack incoming deals
When this is set to false no new sectors will be created for sealing incoming deals
This is useful for forcing all deals to be assigned as snap deals to sectors marked for upgrade`,
		},
		{
			Name: "MakeCCSectorsAvailable",
			Type: "bool",

			Comment: `After sealing CC sectors, make them available for upgrading with deals`,
		},
		{
			Name: "CollateralFromMinerBalance",
			Type: "bool",

			Comment: `Whether to use available miner balance for sector collateral instead of sending it with each message`,
		},
		{
			Name: "AvailableBalanceBuffer",
			Type: "types.FIL",

			Comment: `Minimum available balance to keep in the miner actor before sending it with messages`,
		},
		{
			Name: "DisableCollateralFallback",
			Type: "bool",

			Comment: `Don't send collateral with messages even if there is no available balance in the miner actor`,
		},
		{
			Name: "MaxPreCommitBatch",
			Type: "int",

			Comment: `maximum precommit batch size - batches will be sent immediately above this size`,
		},
		{
			Name: "PreCommitBatchWait",
			Type: "Duration",

			Comment: `how long to wait before submitting a batch after crossing the minimum batch size`,
		},
		{
			Name: "PreCommitBatchSlack",
			Type: "Duration",

			Comment: `time buffer for forceful batch submission before sectors/deal in batch would start expiring`,
		},
		{
			Name: "AggregateCommits",
			Type: "bool",

			Comment: `enable / disable commit aggregation (takes effect after nv13)`,
		},
		{
			Name: "MinCommitBatch",
			Type: "int",

			Comment: `minimum batched commit size - batches above this size will eventually be sent on a timeout`,
		},
		{
			Name: "MaxCommitBatch",
			Type: "int",

			Comment: `maximum batched commit size - batches will be sent immediately above this size`,
		},
		{
			Name: "CommitBatchWait",
			Type: "Duration",

			Comment: `how long to wait before submitting a batch after crossing the minimum batch size`,
		},
		{
			Name: "CommitBatchSlack",
			Type: "Duration",

			Comment: `time buffer for forceful batch submission before sectors/deals in batch would start expiring`,
		},
		{
			Name: "BatchPreCommitAboveBaseFee",
			Type: "types.FIL",

			Comment: `network BaseFee below which to stop doing precommit batching, instead
sending precommit messages to the chain individually. When the basefee is
below this threshold, precommit messages will get sent out immediately.`,
		},
		{
			Name: "AggregateAboveBaseFee",
			Type: "types.FIL",

			Comment: `network BaseFee below which to stop doing commit aggregation, instead
submitting proofs to the chain individually`,
		},
		{
			Name: "MaxSectorProveCommitsSubmittedPerEpoch",
			Type: "uint64",

			Comment: `When submitting several sector prove commit messages simultaneously, this option allows you to
stagger the number of prove commits submitted per epoch
This is done because gas estimates for ProveCommits are non deterministic and increasing as a large
number of sectors get committed within the same epoch resulting in occasionally failed msgs.
Submitting a smaller number of prove commits per epoch would reduce the possibility of failed msgs`,
		},
		{
			Name: "TerminateBatchMax",
			Type: "uint64",

			Comment: ``,
		},
		{
			Name: "TerminateBatchMin",
			Type: "uint64",

			Comment: ``,
		},
		{
			Name: "TerminateBatchWait",
			Type: "Duration",

			Comment: ``,
		},
		{
			Name: "UseSyntheticPoRep",
			Type: "bool",

			Comment: `UseSyntheticPoRep, when set to true, will reduce the amount of cache data held on disk after the completion of PreCommit 2 to 11GiB.`,
		},
		{
			Name: "RequireActivationSuccess",
			Type: "bool",

			Comment: `Whether to abort if any sector activation in a batch fails (newly sealed sectors, only with ProveCommitSectors3).`,
		},
		{
			Name: "RequireActivationSuccessUpdate",
			Type: "bool",

			Comment: `Whether to abort if any piece activation notification returns a non-zero exit code (newly sealed sectors, only with ProveCommitSectors3).`,
		},
		{
			Name: "RequireNotificationSuccess",
			Type: "bool",

			Comment: `Whether to abort if any sector activation in a batch fails (updating sectors, only with ProveReplicaUpdates3).`,
		},
		{
			Name: "RequireNotificationSuccessUpdate",
			Type: "bool",

			Comment: `Whether to abort if any piece activation notification returns a non-zero exit code (updating sectors, only with ProveReplicaUpdates3).`,
		},
	},
	"lotus_config.Splitstore": []DocField{
		{
			Name: "ColdStoreType",
			Type: "string",

			Comment: `ColdStoreType specifies the type of the coldstore.
It can be "discard" (default) for discarding cold blocks, "messages" to store only messages or "universal" to store all chain state..`,
		},
		{
			Name: "HotStoreType",
			Type: "string",

			Comment: `HotStoreType specifies the type of the hotstore.
Only currently supported value is "badger".`,
		},
		{
			Name: "MarkSetType",
			Type: "string",

			Comment: `MarkSetType specifies the type of the markset.
It can be "map" for in memory marking or "badger" (default) for on-disk marking.`,
		},
		{
			Name: "HotStoreMessageRetention",
			Type: "uint64",

			Comment: `HotStoreMessageRetention specifies the retention policy for messages, in finalities beyond
the compaction boundary; default is 0.`,
		},
		{
			Name: "HotStoreFullGCFrequency",
			Type: "uint64",

			Comment: `HotStoreFullGCFrequency specifies how often to perform a full (moving) GC on the hotstore.
A value of 0 disables, while a value 1 will do full GC in every compaction.
Default is 20 (about once a week).`,
		},
		{
			Name: "HotStoreMaxSpaceTarget",
			Type: "uint64",

			Comment: `HotStoreMaxSpaceTarget sets a target max disk size for the hotstore. Splitstore GC
will run moving GC if disk utilization gets within a threshold (150 GB) of the target.
Splitstore GC will NOT run moving GC if the total size of the move would get
within 50 GB of the target, and instead will run a more aggressive online GC.
If both HotStoreFullGCFrequency and HotStoreMaxSpaceTarget are set then splitstore
GC will trigger moving GC if either configuration condition is met.
A reasonable minimum is 2x fully GCed hotstore size + 50 G buffer.
At this minimum size moving GC happens every time, any smaller and moving GC won't
be able to run. In spring 2023 this minimum is ~550 GB.`,
		},
		{
			Name: "HotStoreMaxSpaceThreshold",
			Type: "uint64",

			Comment: `When HotStoreMaxSpaceTarget is set Moving GC will be triggered when total moving size
exceeds HotstoreMaxSpaceTarget - HotstoreMaxSpaceThreshold`,
		},
		{
			Name: "HotstoreMaxSpaceSafetyBuffer",
			Type: "uint64",

			Comment: `Safety buffer to prevent moving GC from overflowing disk when HotStoreMaxSpaceTarget
is set.  Moving GC will not occur when total moving size exceeds
HotstoreMaxSpaceTarget - HotstoreMaxSpaceSafetyBuffer`,
		},
	},
	"lotus_config.StorageMiner": []DocField{
		{
			Name: "Subsystems",
			Type: "MinerSubsystemConfig",

			Comment: ``,
		},
		{
			Name: "Dealmaking",
			Type: "DealmakingConfig",

			Comment: ``,
		},
		{
			Name: "Proving",
			Type: "ProvingConfig",

			Comment: ``,
		},
		{
			Name: "Sealing",
			Type: "SealingConfig",

			Comment: ``,
		},
		{
			Name: "Storage",
			Type: "SealerConfig",

			Comment: ``,
		},
		{
			Name: "Fees",
			Type: "MinerFeeConfig",

			Comment: ``,
		},
		{
			Name: "Addresses",
			Type: "MinerAddressConfig",

			Comment: ``,
		},
		{
			Name: "HarmonyDB",
			Type: "HarmonyDB",

			Comment: ``,
		},
	},
	"lotus_config.Wallet": []DocField{
		{
			Name: "RemoteBackend",
			Type: "string",

			Comment: ``,
		},
		{
			Name: "EnableLedger",
			Type: "bool",

			Comment: ``,
		},
		{
			Name: "DisableLocal",
			Type: "bool",

			Comment: ``,
		},
	},
}
